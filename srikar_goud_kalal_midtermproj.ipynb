{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48770bb0-44dd-469d-878d-9e91fa638010",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "from math import comb\n",
    "from itertools import combinations\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "from mlxtend.frequent_patterns import fpgrowth, association_rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aeee2e6-1bb6-4763-9e10-263d9d2603ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_display_dataset(choice):\n",
    "    dataset_paths = {\n",
    "        1: 'amazon.csv',\n",
    "        2: 'bestbuy.csv',\n",
    "        3: 'kmart.csv',\n",
    "        4: 'nike.csv',\n",
    "        5: 'generic.csv'\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        if choice in dataset_paths:\n",
    "            df = pd.read_csv(dataset_paths[choice])\n",
    "            return df\n",
    "        else:\n",
    "            print(\"Invalid choice. Please select a number between 1 and 5.\")\n",
    "            return None\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found for choice {choice}. Please check the file path and try again.\")\n",
    "        return None\n",
    "\n",
    "try:\n",
    "    choice = int(input(\"Please, Select your Dataset for \\n 1 Amazon.\\n 2 BestBuy.\\n 3 K-Mart.\\n 4 Nike.\\n 5 Generic. \\n\"))\n",
    "    df = load_and_display_dataset(choice)\n",
    "    if df is not None:\n",
    "        print(df)\n",
    "except ValueError:\n",
    "    print(\"Please enter a valid integer.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a25dda4-d99e-4655-9ca2-9195e84f54ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_sup = input(\"Please, input your Min. Support in percentage (0-100) \\n\")\n",
    "min_sup = float(min_sup) / 100  # Convert percentage to fraction\n",
    "\n",
    "min_con = input(\"Please, input your Min. Confidence in percentage (0-100) \\n\")\n",
    "min_con = float(min_con) / 100  # Convert percentage to fraction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37906c0-75d6-4fbd-8ff3-2750d2bc0bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the 'Transaction' column by splitting the string into a list of items\n",
    "df['Transaction'] = df['Transaction'].apply(lambda x: x.split(','))\n",
    "\n",
    "# Extract unique transactions and items for preprocessing\n",
    "unique_transactions = df['Transaction ID'].unique()\n",
    "transaction_items = df['Transaction'].tolist()\n",
    "\n",
    "# Since every transaction is unique, we can directly use the transaction_items for analysis\n",
    "transactions = transaction_items\n",
    "\n",
    "# frequent items\n",
    "def frequent_items(new_patterns, current_items):\n",
    "    items_in_patterns = set(item for pattern in new_patterns for item in pattern)\n",
    "    return [item for item in current_items if item in items_in_patterns]\n",
    "\n",
    "# frequent patterns\n",
    "def find_frequent_patterns(transactions, min_support):\n",
    "    unique_items = set(item for sublist in transactions for item in sublist)\n",
    "    pattern_size = 1\n",
    "    frequent_patterns = []\n",
    "    frequent_patterns_count = []\n",
    "    current_frequent_items = list(unique_items)\n",
    "    while current_frequent_items:\n",
    "        potential_patterns = combinations(current_frequent_items, pattern_size)\n",
    "        new_frequent_patterns = []\n",
    "        for pattern in list(potential_patterns):\n",
    "            count = sum(1 for transaction in transactions if set(pattern).issubset(set(transaction)))\n",
    "            if count >= min_support * len(transactions):\n",
    "                new_frequent_patterns.append(pattern)\n",
    "                frequent_patterns_count.append(count)\n",
    "        frequent_patterns.extend(new_frequent_patterns)\n",
    "        pattern_size += 1\n",
    "        current_frequent_items = frequent_items(new_frequent_patterns, current_frequent_items)\n",
    "    return frequent_patterns, frequent_patterns_count\n",
    "\n",
    "def generate_association_rules(frequent_patterns, frequent_patterns_count, transactions, min_confidence):\n",
    "    rules_with_confidence = []\n",
    "    for pattern, pattern_count in zip(frequent_patterns, frequent_patterns_count):\n",
    "        if len(pattern) > 1:\n",
    "            sub_patterns = [sub_pattern for i in range(1, len(pattern))\n",
    "                            for sub_pattern in combinations(pattern, i)]\n",
    "            for sub_pattern in sub_patterns:\n",
    "                sub_pattern_count = sum(1 for transaction in transactions if set(sub_pattern).issubset(set(transaction)))\n",
    "                if sub_pattern_count > 0:  # Avoid division by zero\n",
    "                    confidence = pattern_count / sub_pattern_count\n",
    "                    if confidence >= min_confidence:\n",
    "                        consequence = set(pattern) - set(sub_pattern)\n",
    "                        rules_with_confidence.append(((tuple(sub_pattern), tuple(consequence)), confidence))\n",
    "    return rules_with_confidence\n",
    "\n",
    "def format_rules_for_printing(rules_with_confidence):\n",
    "    formatted_rules = []\n",
    "    for (antecedent, consequent), confidence in rules_with_confidence:\n",
    "        rule_string = f\"{antecedent} ---> {consequent} with confidence = {confidence:.2f}\"\n",
    "        formatted_rules.append(rule_string)\n",
    "    return formatted_rules\n",
    "# Start timing\n",
    "start_time = time.time()\n",
    "# Find frequent patterns and rules\n",
    "frequent_patterns, frequent_patterns_count = find_frequent_patterns(transactions, min_sup)\n",
    "rules_with_confidence = generate_association_rules(frequent_patterns, frequent_patterns_count, transactions, min_con)\n",
    "# End timing\n",
    "end_time = time.time()\n",
    "bruteapriori_runtime = end_time - start_time\n",
    "\n",
    "formatted_rules = format_rules_for_printing(rules_with_confidence)\n",
    "\n",
    "# Function to print frequent patterns and association rules\n",
    "def print_frequent_patterns_and_rules(frequent_patterns, frequent_patterns_count, transactions, min_confidence,formatted_rules):\n",
    "    print(\"Frequent patterns:\\n\")\n",
    "    for pattern, count in zip(frequent_patterns, frequent_patterns_count):\n",
    "        print(f\"{pattern}, support: {count/len(transactions):.2f}\")\n",
    "    print('\\nAssociation rules:')\n",
    "    for rule in formatted_rules:\n",
    "        print(rule)\n",
    "\n",
    "# Print the frequent patterns and rules\n",
    "print_frequent_patterns_and_rules(frequent_patterns, frequent_patterns_count, transactions, min_con,formatted_rules)\n",
    "\n",
    "print(f\"Brute-forced Apriori runtime: {bruteapriori_runtime} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83aa480b-621e-4ff2-b2e6-69a4c6c96552",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize TransactionEncoder\n",
    "te = TransactionEncoder()\n",
    "te_ary = te.fit(transactions).transform(transactions)\n",
    "df_encoded = pd.DataFrame(te_ary, columns=te.columns_)\n",
    "\n",
    "# Start timing\n",
    "start_time = time.time()\n",
    "\n",
    "# Apriori algorithm\n",
    "frequent_itemsets = apriori(df_encoded, min_support=min_sup, use_colnames=True)\n",
    "\n",
    "# Generate association rules\n",
    "rules = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=min_con)\n",
    "\n",
    "# End timing\n",
    "end_time = time.time()\n",
    "apriori_runtime = end_time - start_time\n",
    "\n",
    "# Function to display output similar to the brute-force method\n",
    "def display_output_like_brute_force(frequent_itemsets, rules):\n",
    "    print(\"Frequent patterns:\\n\")\n",
    "    for index, row in frequent_itemsets.iterrows():\n",
    "        print(f\"{list(row['itemsets'])}, support: {row['support']}\")\n",
    "\n",
    "    print(\"\\nAssociation rules:\")\n",
    "    for index, row in rules.iterrows():\n",
    "        print(f\"{list(row['antecedents'])} ---> {list(row['consequents'])} with confidence = {row['confidence']:.2f}\")\n",
    "\n",
    "display_output_like_brute_force(frequent_itemsets, rules)\n",
    "\n",
    "print(f\"Apriori runtime: {apriori_runtime} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f96a91-fdc3-48e5-b73b-fbb6e62e04ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start timing\n",
    "start_time = time.time()\n",
    "\n",
    "# Find frequent itemsets with the fpgrowth algorithm\n",
    "frequent_itemsets_fp = fpgrowth(df_encoded, min_support=0.1, use_colnames=True)\n",
    "\n",
    "# Generate association rules\n",
    "rules_fp = association_rules(frequent_itemsets_fp, metric=\"confidence\", min_threshold=0.1)\n",
    "\n",
    "# End timing\n",
    "end_time = time.time()\n",
    "fpgrowth_runtime = end_time - start_time\n",
    "\n",
    "# Function to display output similar to the brute-force method\n",
    "def display_output_like_brute_force(frequent_itemsets, rules):\n",
    "    print(\"Frequent patterns:\\n\")\n",
    "    for index, row in frequent_itemsets.iterrows():\n",
    "        print(f\"{list(row['itemsets'])}, support: {row['support']}\")\n",
    "\n",
    "    print(\"\\nAssociation rules:\")\n",
    "    for index, row in rules.iterrows():\n",
    "        print(f\"{list(row['antecedents'])} ---> {list(row['consequents'])} with confidence = {row['confidence']:.2f}\")\n",
    "\n",
    "# Display the formatted output\n",
    "display_output_like_brute_force(frequent_itemsets_fp, rules_fp)\n",
    "\n",
    "print(f\"FP-Growth runtime: {fpgrowth_runtime} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20072909-c74e-4fb4-bbb2-cd0da79c979b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"Algorithm\": [\"BruteApriori\", \"Apriori\", \"FPGrowth\"],\n",
    "    \"Runtime\": [bruteapriori_runtime, apriori_runtime, fpgrowth_runtime]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df_sorted = df.sort_values(by=\"Runtime\", ascending=True)\n",
    "print(df_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096c6356-b1a5-4703-8ac5-94d54f86045f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
